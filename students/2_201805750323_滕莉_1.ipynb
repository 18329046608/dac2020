{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'http.client.HTTPResponse'>\n",
      "b'<html>\\r\\n<head>\\r\\n\\t<script>\\r\\n\\t\\tlocation.replace(location.href.replace(\"https://\",\"http://\"));\\r\\n\\t</script>\\r\\n</head>\\r\\n<body>\\r\\n\\t<noscript><meta http-equiv=\"refresh\" content=\"0;url=http://www.baidu.com/\"></noscript>\\r\\n</body>\\r\\n</html>'\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "##网页抓取\n",
    "\n",
    "#用urllib.requests库发起一次get请求\n",
    "import urllib.request\n",
    "response = urllib.request.urlopen(\"https://www.baidu.com\") \n",
    "print(type(response))\n",
    "print(response.read())    #返回网页内容\n",
    "print(response.status)    #返回结果的状态码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.baidu.com/\n"
     ]
    }
   ],
   "source": [
    "#用Requests库伪装成火狐浏览器发起一次post请求\n",
    "import requests\n",
    "url = \"https://www.baidu.com\"\n",
    "headers = {\n",
    "#伪装⼀个⽕狐浏览器\n",
    "\"User-Agent\":'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'\n",
    ",\"host\":'httpbin.org'\n",
    "}\n",
    "response= requests.post(url,headers=headers) #用post方法获取请求\n",
    "print(response.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\r\n",
      "<!--STATUS OK--><html> <head><meta http-equiv=content-type content=text/html;charset=utf-8><meta http-equiv=X-UA-Compatible content=IE=Edge><meta content=always name=referrer><link rel=stylesheet type=text/css href=https://ss1.bdstatic.com/5eN1bjq8AAUYm2zgoY3K/r/www/cache/bdorz/baidu.min.css><title>ç¾åº¦ä¸ä¸ï¼ä½ å°±ç¥é</title></head> <body link=#0000cc> <div id=wrapper> <div id=head> <div class=head_wrapper> <div class=s_form> <div class=s_form_wrapper> <div id=lg> <img hidefocus=true src=//www.baidu.com/img/bd_logo1.png width=270 height=129> </div> <form id=form name=f action=//www.baidu.com/s class=fm> <input type=hidden name=bdorz_come value=1> <input type=hidden name=ie value=utf-8> <input type=hidden name=f value=8> <input type=hidden name=rsv_bp value=1> <input type=hidden name=rsv_idx value=1> <input type=hidden name=tn value=baidu><span class=\"bg s_ipt_wr\"><input id=kw name=wd class=s_ipt value maxlength=255 autocomplete=off autofocus=autofocus></span><span class=\"bg s_btn_wr\"><input type=submit id=su value=ç¾åº¦ä¸ä¸ class=\"bg s_btn\" autofocus></span> </form> </div> </div> <div id=u1> <a href=http://news.baidu.com name=tj_trnews class=mnav>æ°é»</a> <a href=https://www.hao123.com name=tj_trhao123 class=mnav>hao123</a> <a href=http://map.baidu.com name=tj_trmap class=mnav>å°å¾</a> <a href=http://v.baidu.com name=tj_trvideo class=mnav>è§é¢</a> <a href=http://tieba.baidu.com name=tj_trtieba class=mnav>è´´å§</a> <noscript> <a href=http://www.baidu.com/bdorz/login.gif?login&amp;tpl=mn&amp;u=http%3A%2F%2Fwww.baidu.com%2f%3fbdorz_come%3d1 name=tj_login class=lb>ç»å½</a> </noscript> <script>document.write('<a href=\"http://www.baidu.com/bdorz/login.gif?login&tpl=mn&u='+ encodeURIComponent(window.location.href+ (window.location.search === \"\" ? \"?\" : \"&\")+ \"bdorz_come=1\")+ '\" name=\"tj_login\" class=\"lb\">ç»å½</a>');\r\n",
      "                </script> <a href=//www.baidu.com/more/ name=tj_briicon class=bri style=\"display: block;\">æ´å¤äº§å</a> </div> </div> </div> <div id=ftCon> <div id=ftConw> <p id=lh> <a href=http://home.baidu.com>å",
      "³äºç¾åº¦</a> <a href=http://ir.baidu.com>About Baidu</a> </p> <p id=cp>&copy;2017&nbsp;Baidu&nbsp;<a href=http://www.baidu.com/duty/>ä½¿ç¨ç¾åº¦åå¿",
      "è¯»</a>&nbsp; <a href=http://jianyi.baidu.com/ class=cp-feedback>æè§åé¦</a>&nbsp;äº¬ICPè¯030173å·&nbsp; <img src=//www.baidu.com/img/gs.gif> </p> </div> </div> </div> </body> </html>\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#用Request库中的session对象发出post请求\n",
    "import requests,json\n",
    "session = requests.session() #创建会话\n",
    "url = \"https://www.baidu.com\"\n",
    "headers = {\n",
    "'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36'\n",
    "}  #添加请求头\n",
    "mycookie = { \"PHPSESSID\":\"56v9clgo1kdfo3q5q8ck0aaaaa\"} #设置cookies值\n",
    "html = session.get(url,cookies=mycookie).text\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#实现深度优先爬取\n",
    "count = 0\n",
    "r = re.compile(r'href=[\\'\"]?(/item[^\\'\" >]+)') # 抽取所需链接信息的正则语言规则\n",
    "seed = \"/item/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB\" # 这是网络爬虫词条\n",
    "stack = [seed] # 设置种子链接的栈（使用列表模拟栈）\n",
    "storage = {}\n",
    "while count < 5:\n",
    "    try:\n",
    "        url = stack.pop(-1) # 取出栈的最后一条URL\n",
    "        html = ur.urlopen(\"https://baike.baidu.com\"+url).read().decode('utf-8') # 对URL进行拼接\n",
    "        new_urls = r.findall(html) # 提取当前网页下的所有链接URL信息\n",
    "        print(new_urls)\n",
    "        stack.extend(new_urls) # 将新提取的链接信息入队列\n",
    "        storage[url] = len(new_urls)\n",
    "        count += 1\n",
    "    except Exception as e:\n",
    "        print(url)\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抓取网页的去重广度优先遍历\n",
    "count = 0 # 层数\n",
    "floors = 1 # 限制爬取的层数\n",
    "lastStep = []\n",
    "r = re.compile(r'href=[\\'\"]?(/item[^\\'\" >]+)') #使用正则表达式\n",
    "seed = '/item/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB' # 这是网络爬虫词条\n",
    "queue = [[seed]]\n",
    "for i in range(floors): # 限制爬取范围在设定的层数范围内\n",
    "    queue.append([])\n",
    "storage = {}\n",
    "used = set() # 设置集合存放爬取过的url\n",
    "while len(queue[0])>0 or count!=0: # 种子队列不为空或者层数不为零\n",
    "    try:\n",
    "        url = queue[count].pop(-1)\n",
    "        print(url+\" \"+str(count)) # 打印当前链接和层数\n",
    "        html = ur.urlopen('https://baike.baidu.com'+url).read().decode('utf-8')\n",
    "        storage[url]=html\n",
    "        used.add(url) # 将爬取过的URL放入集合中\n",
    "        new_urls = r.findall(html)\n",
    "        if count < floors:\n",
    "            for new_url in set(new_urls):\n",
    "                if new_url not in used and new_url not in queue:#判断新链接网址中的包含的链接是否为重复的\n",
    "                    queue[count+1].append(new_url) # 将爬取的URL存入到队列中相应层数的列表\n",
    "            count+=1\n",
    "        else:\n",
    "            if len(queue[count])==0:\n",
    "                count -= 1\n",
    "    except Exception as e:\n",
    "        print(url)\n",
    "        print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抓取网页的不去重广度优先遍历\n",
    "count = 0\n",
    "r = re.compile(r'href=[\\'\"]?(/item[^\\'\" >]+)') # 抽取所需链接信息的正则语言规则\n",
    "seed = \"/item/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB\" # 这是网络爬虫词条\n",
    "queue = [seed] # 设置种子链接的队列（使用列表模拟队列）\n",
    "storage = {}\n",
    "while count < 8:\n",
    "    try:\n",
    "        url = queue.pop(0) # 取出队列最后一条URL\n",
    "        html = ur.urlopen(\"https://baike.baidu.com\"+url).read().decode('utf-8') # 对URL进行拼接\n",
    "        new_urls = r.findall(html) # 提取当前网页下的所有链接URL信息\n",
    "        print(new_urls)\n",
    "        queue.extend(new_urls) # 将新提取的链接信息入队列\n",
    "        storage[url] = len(new_urls)\n",
    "        count += 1\n",
    "    except Exception as e:\n",
    "        print(url)\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
