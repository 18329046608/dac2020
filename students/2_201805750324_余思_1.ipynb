{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 《数据采集与清洗》\n",
    "## 第一次作业内容： 网页抓取\n",
    "### 具体目标：\n",
    "+ 用``urllib.requests``库发起一次``get``请求，输出``response``文本信息；\n",
    "+ 用``Requests``库伪装成火狐浏览器发起一次``post``请求，输出``response``文本信息；\n",
    "+ 用``Requests``库中的``session``对象发出``get``请求，设置``cookies``并获取，输出获取的``cookies``内容；\n",
    "+ 实现抓取网页的不去重深度遍历算法，自选合适的种子网站和相关参数，输出结果；\n",
    "+ 编写抓取网页的广度遍历算法（含去重和不去重），自选合适的种子网站和相关参数，输出结果；\n",
    "+ (选)将抓取网页的去重深度遍历算法封装成对象（类），并测试。\n",
    "\n",
    "### 注：\n",
    "+ 代码要有注释，结果要有分析；\n",
    "+ 本次作业提交截至时间：2020年3月10日(星期二)；\n",
    "+ 文件命名规则: 班级号+学号+姓名，示例：``1_20188989899_张三``；\n",
    "+ 提交方式：1班发送至邮箱：632994085@qq.com；2班发送至邮箱：786888939@qq.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题1：用``urllib.requests``库发起一次``get``请求，输出``response``文本信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里编写代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request,parse\n",
    "url = 'https://www.12306.cn/get' #输入要爬取的网页\n",
    "headers = {\n",
    "    #伪装一个火狐浏览器\n",
    "    'User-Agent':'Mozilla/4.0(compatible;MSIE 5.5;Windows NT)',\n",
    "    'host':'www.12306.cn'\n",
    "}\n",
    "dict = {\n",
    "    'name':'Hackdata'\n",
    "}\n",
    "data = bytes(parse.urlencode(dict),encoding = 'utf8')\n",
    "req = request.Request(url = url,data = data,headers = headers,method = 'POST')\n",
    "response = request.urlopen(req) #使用urlopen函数向网页发出请求\n",
    "print(response.read().decode('utf-8'))#使用read函数读取相应内容，将响应内容转化为utf-8格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里对结果进行分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用``Requests``库伪装成火狐浏览器发起一次``post``请求，输出``response``文本信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "payload_tuples = [('key1', 'value1'), ('key1', 'value2')]\n",
    "r1 = requests.post('http://www.12306.cn/post', data=payload_tuples)\n",
    "payload_dict = {'key1': ['value1', 'value2']}\n",
    "r2 = requests.post('http://www.12306.cn/post', data=payload_dict)\n",
    "print(r1.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里对结果进行分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用``Requests``库中的``session``对象发出``get``请求，设置``cookies``并获取，输出获取的``cookies``内容。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里编写代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "s = requests.Session()#创建一个Session对象\n",
    "r = s.get('https://www.12306.cn/cookies')\n",
    "print(r.text)#打印出cookies的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里对结果进行分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实现抓取网页的不去重深度遍历算法，自选合适的种子网站和相关参数，输出结果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里编写代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re\n",
    "count = 10\n",
    "r = re.compile(r'href=[\\'\"]?(http[^\\'\" >]+)')#给定正则化的格式\n",
    "seed = 'http://www.12306.cn/'  #输入要爬取的网页\n",
    "stack = [seed]\n",
    "storage = {}\n",
    "while len(queue) > 0 and count > 0:\n",
    "    try:\n",
    "        url = stack.pop(-1)\n",
    "        html = requests.get(url).text\n",
    "        #将新发新未抓取的URL添加到queue中\n",
    "        new_urls = r.findall(html)\n",
    "        stack.extend(new_urls)\n",
    "        storage[url] = len(new_urls)\n",
    "        count -= 1\n",
    "    except Exception as e:#报错提醒\n",
    "        print(url)\n",
    "        print(e) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里对结果进行分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编写抓取网页的广度遍历算法（含去重和不去重），自选合适的种子网站和相关参数，输出结果。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里编写代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://forecast.lytq.com/pc.html\n",
      "http://www.china-railway.com.cn/\n",
      "http://www.china-ric.com/\n",
      "http://www.95306.cn/\n",
      "http://www.cre.cn/\n",
      "http://www.weather.com.cn/weather1d/\n",
      "http://mail.china-railway.com.cn/\n",
      "http://weibo.com/chineserailways\n",
      "https://www.12306.cn/index/\n",
      "http://www.95306.cn/\n",
      "http://rczp.china-railway.com.cn\n",
      "http://www.china-railway.com.cn/h/\n",
      "http://wzcgzs.95306.cn/mainPage.do\n",
      "http://tv.cctv.com/v/v2/VIDEn3hUShuG1gUWm4pHLEgX200308.html?spm=C31267.PFsKSaKh6QQC.S71105.19\n",
      "http://tv.cctv.com/2020/03/07/VIDEjm2r5vY9qwsFRsc6FiLW200307.shtml?spm=C31267.PFsKSaKh6QQC.S71105.10\n",
      "http://tv.cctv.com/v/v2/VIDEn3hUShuG1gUWm4pHLEgX200308.html?spm=C31267.PFsKSaKh6QQC.S71105.19\n",
      "http://tv.cctv.com/2020/03/07/VIDEjm2r5vY9qwsFRsc6FiLW200307.shtml?spm=C31267.PFsKSaKh6QQC.S71105.10\n",
      "http://tv.cctv.com/v/v2/VIDEn3hUShuG1gUWm4pHLEgX200308.html?spm=C31267.PFsKSaKh6QQC.S71105.19\n",
      "http://tv.cctv.com/2020/03/07/VIDEjm2r5vY9qwsFRsc6FiLW200307.shtml?spm=C31267.PFsKSaKh6QQC.S71105.10\n",
      "http://tv.cctv.com/v/v2/VIDEOABFpldoCebYVr8w0knH200302.html\n",
      "http://tv.cctv.com/v/v2/VIDEPpPhcvPvxGCvo8pFFp6f200301.html\n",
      "https://xhpfmapi.zhongguowangshi.com/vh512/share/8936375?channel=weixin\n",
      "https://www.uichighspeed2020.com\n",
      "https://mp.weixin.qq.com/s/Zl-Liccl6I6o3Gie0vC-rg\n",
      "https://www.12306.cn/index/\n",
      "http://www.95306.cn/\n",
      "http://rczp.china-railway.com.cn\n",
      "http://www.china-railway.com.cn/h/\n",
      "http://wzcgzs.95306.cn/mainPage.do\n",
      "http://www.gov.cn/\n",
      "http://www.fmprc.gov.cn\n",
      "http://www.mod.gov.cn/\n",
      "http://www.sdpc.gov.cn\n",
      "http://www.moe.edu.cn\n",
      "http://www.most.gov.cn\n",
      "http://www.miit.gov.cn/\n",
      "http://www.seac.gov.cn\n",
      "http://www.mps.gov.cn\n",
      "http://www.mca.gov.cn\n",
      "http://www.moj.gov.cn/\n",
      "http://www.mof.gov.cn\n",
      "http://www.mohrss.gov.cn\n",
      "http://www.mnr.gov.cn/\n",
      "http://www.mee.gov.cn/\n",
      "http://www.mohurd.gov.cn\n",
      "http://www.mot.gov.cn/\n",
      "http://www.mwr.gov.cn\n",
      "http://www.moa.gov.cn/\n",
      "http://www.mofcom.gov.cn\n",
      "https://www.mct.gov.cn/\n",
      "http://www.nhc.gov.cn/\n",
      "http://www.mva.gov.cn/\n",
      "http://www.chinasafety.gov.cn/index.shtml\n",
      "http://www.pbc.gov.cn\n",
      "http://www.audit.gov.cn\n",
      "http://www.nra.gov.cn/\n",
      "http://www.12306.cn\n",
      "http://www.95306.cn/\n",
      "http://www.rebcenter.com/\n",
      "http://wzcgzs.95306.cn/mainPage.do\n",
      "http://rczp.china-railway.com.cn\n",
      "http://www.peoplerail.com/\n",
      "http://www.tdpress.com/\n",
      "http://www.china-rail.org.cn/\n",
      "http://www.sytlj.com/\n",
      "http://www.whrailway.cn/\n",
      "http://www.jntlj.com/\n",
      "http://www.gzrailway.com.cn/\n",
      "http://www.nntlj.com/\n",
      "http://www.cd-rail.cn/\n",
      "http://www.crscsc.com.cn/\n",
      "http://www.cre.cn/\n",
      "http://www.crct.com/\n",
      "http://www.tsdig.com/\n",
      "http://www.cric-china.com.cn/\n",
      "https://www.zhongtieyintong.com/\n",
      "http://www.rails.cn/\n",
      "http://www.crecc.com.cn/\n",
      "http://www.crnet.com.cn/\n",
      "http://www.crs.org.cn/\n",
      "http://www.china-dftlxh.cn/\n",
      "http://www.carec.org.cn/\n",
      "http://www.crrcgc.cc/\n",
      "http://www.crsc.cn/\n",
      "http://www.crecg.com/\n",
      "http://www.crcc.cn/\n",
      "http://www.ccccltd.cn/\n",
      "https://www.crmsc.com.cn/\n"
     ]
    }
   ],
   "source": [
    "#不去重\n",
    "import requests,re\n",
    "count=3\n",
    "r=re.compile(r'href=[\\'\"]?(http[^\\'\">]+)') #给定正则化的格式\n",
    "seed=\"https://www.12306.cn/\" #输入要爬取的网页\n",
    "queue=[seed]\n",
    "while len(queue) > 0 and count > 0:\n",
    "    url=queue.pop(0)\n",
    "    html=requests.get(url,timeout=5).text \n",
    "    #将新发新未抓取的URL添加到queue中\n",
    "    new_urls=r.findall(html)  \n",
    "    for new_url in new_urls:\n",
    "        print(new_url)#打印出url\n",
    "        queue.append(new_url) #将url入队\n",
    "    count=count-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#去重\n",
    "import requests,re\n",
    "count=3\n",
    "recount=0\n",
    "allcount=1\n",
    "r=re.compile(r'href=[\\'\"]?(http[^\\'\">]+)') #给定正则化的格式\n",
    "seed=\"https://www.12306.cn/\" #输入要爬取的网页\n",
    "queue=[seed]\n",
    "used=set() #存储爬取过的url\n",
    "storage={}  \n",
    "while len(queue) > 0 and count >  0 :\n",
    "    try:\n",
    "        url=queue.pop(0)\n",
    "        html=requests.get(url,timeout=5).text  \n",
    "        storage[url]=html\n",
    "        used.add(url)\n",
    "        #将新发新未抓取的URL添加到queue中\n",
    "        new_urls=r.findall(html)\n",
    "        for new_url in new_urls:#进行深度递归\n",
    "            allcount += 1\n",
    "            if new_url not in used and new_url not in queue:\n",
    "                queue.append(new_url)\n",
    "                print(new_url)#打印出url\n",
    "            else:\n",
    "                recount =+ 1\n",
    "    except Exception as e:#报错提醒\n",
    "        print(url)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里对结果进行分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (选)将抓取网页的去重深度遍历算法封装成对象（类），并测试。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里编写代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里对结果进行分析。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
